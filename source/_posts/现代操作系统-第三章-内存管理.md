---
title: 现代操作系统-第三章-内存管理
top: false
cover: false
toc: true
mathjax: true
date: 2020-09-10 09:43:36
password:
summary:
tags:
categories: 操作系统
thumbnail:
---

虽然上一章说要挑自己感兴趣的看，但发现知识储备并不支持我这么做，所以还是按顺序看了下去。

内存（RAM）是计算机中重要且基本的一个组成部分，需要认真管理。每个程序员都梦想拥有这样的存储器：它是私有的、内容无限大的、速度无限快的、永久性的（即断电时不会丢失数据），并且价格低廉。遗憾的是，目前这样的存储器还不存在。现实中，我们使用的是分层存储器体系（memory hierarchy）的概念。
在这个体系中，计算机有若干MB快速、昂贵且易失的高速缓存（cache），若干GB速度与价格适中但易失的内存，以及若干TB低速、廉价、非易失的磁盘存储，另外还有U盘和记忆卡等可移动存储装置。操作系统的工作是将这个存储体系抽象为一个有用的模型并管理这个抽象模型。
操作系统中管理分层存储体系的部分称为存储管理器（memory manager）。它的任务是有效地管理内存，即记录哪些内存是正在使用的，哪些内存是空闲的；在进程需要时为其分配内存，在进程使用完后释放内存。

<!--more-->

## 无存储器抽象
最简单的存储器抽象就是根本没有抽象，即每个程序都直接访问物理内存。
在这种情况下，想要在内存中同时运行两个程序是不可能的。如果第一个程序在2000的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，因为程序直接指定了物理内存的位置，所以同时运行两个程序行不通。

不过也存在一些变通的方法。

![](/images/现代操作系统/系统进程和用户进程使用不同的内存位置.png)

这样的变通方法允许操作系统进程运行的同时，再运行一个用户进程。第一种方案以前被用在大型机和小型计算机上，现在很少使用了。第二种方案被用在一些掌上电脑和嵌入式系统中。第三种方案用于早期的个人计算机中（例如运行MS-DOS的计算机），在RAM中的系统部分称为BIOS（Basic Input Output System）。第一种和第三种方案的缺点是用户程序出现的错误可能摧毁操作系统，引发灾难性的后果。
在没有存储器抽象的系统中实现并行的一种方法是使用多线程来编程。虽然这个想法行得通，但没有被广泛使用，因为人们通常希望能够在同一时间运行没有关联的程序，而这是线程抽象所不能提供的。

**在不使用存储器抽象的情况下运行多个程序**
更进一步的方法是，将当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入内存运行，只要同一时间中只有一个程序在运行，就不会发生冲突。这么做的弊端是显而易见的，慢，但是这个交换的思想在后面会继续讨论。
另外是借助特殊的硬件来实现。IBM 360的早期模型是这样解决的：内存被划分为2KB的块，每一块被分配一个4位的保护键，保护键存储在CPU的特殊寄存器中。运行中的程序如果访问了不属于它的内存地址，那么该地址的保护键和程序状态字中的保护键就会冲突，360的硬件就会捕获到这一事件，从而防止进程之间互相干扰。
然而，这仍然没有解决程序访问绝对物理地址而造成互相之间冲突的问题。IBM 360使用静态重定位技术：当一个程序被装载到地址16384时，常数16384会被加到每一个程序地址上。但这不是一种通用的解决方法，同时会减慢装载速度，而且它要求给所有的可执行程序提供额外的信息来区分哪些内存字中存有（可重定位的）地址，哪些没有，比如
```
MOV REGISTER1, 28
```
这样把数28送到REGISTER1的指令不可以被重定位。

虽然直接引用物理地址对于大型计算机、小型计算机和个人电脑来说已经是很久远的记忆了，但是这种缺少存储器抽象的情况在嵌入式系统和智能卡系统中还是很常见的，比如收音机、洗衣机、微波炉这样的设备已经完全被（ROM形式的）软件控制，因为它们运行的所有程序都是可以事先确定的。

## 一种存储器抽象：地址空间
把物理地址暴露给进程会带来以下几个严重问题：
1. 如果用户程序可以访问内存的每个地址，那么它们就可以很容易地破坏操作系统，造成系统崩溃
2. 同时运行多个程序是非常困难的，而这种需求十分常见
因此，我们需要想想其他办法。

### 地址空间的概念
要使多个应用程序同时处于内存中且相互不影响，需要解决两个问题：保护和重定位。一个比IBM 360使用的静态重定位技术更好的方法是创造一个新的存储器抽象：地址空间。
就像进程的概念创造了一类抽象的CPU以运行程序一样，地址空间为程序创造了一种抽象的内存。地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有自己的地址空间，并且这个地址空间独立于其他进程的地址空间。

**基址寄存器与界限寄存器**
这个简单的解决办法是使用动态重定位，简单地把每个进程的地址空间映射到物理内存的不同部分。我们为每个CPU配置两个特殊的硬件寄存器，通常叫做基址寄存器和界限寄存器。
当使用基址寄存器和界限寄存器时，程序装载到内存中连续的空闲位置且装载过程中无需重定位

![](/images/现代操作系统/基址寄存器和界限寄存器.png)

每次进程访问内存，取一条指令，读或者写一个数据字，CPU硬件会把地址发送到内存总线前，自动把基址寄存器中的值加到该地址值上，同时检查它是否等于或大于界限寄存器中的值。这样，对于图中白色部分的程序第一条指令
```
JMP 28
```
就会被硬件解释成
```
JMP 16412
```
这样，程序就如我们所愿地跳转到了CMP指令。
使用基址寄存器和界限寄存器重定位的缺点是，每次访问内存都需要进行加法和比较运算，比较运算可以很快，但加法运算在没有使用特殊电路的情况下会显得很慢。

### 交换技术
如果计算机物理内存足够大，那么之前所提及的所有方案多多少少是可行的，但实际上，内存总是不够用。一个典型的Windows、OS X或Linux系统，在计算机完成引导后会启动50～100个甚至更多的进程，而仅仅一个Photoshop用户程序一启动就轻易地占据了500M内存，而开始处理数据后可能需要数GB的空间。因此，把所有进程保存在内存中需要巨大的内存，如果内存不够，就做不到这一点。
有两种处理内存超载的通用方法。最简单的策略是交换（swapping）技术，即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。另一种策略是虚拟内存（virtual memory），该策略甚至能使程序在只有一部分被调入内存的情况下运行。
下面讨论交换策略。

![](/images/现代操作系统/交换内存.png)

交换在内存中产生了多个空闲区（hole，也称为空洞），通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块，该技术被称为内存紧缩（memory compaction），通常不进行这个操作，因为很费CPU时间。
如果进程在创建后所需内存大小不变，则分配时很简单，系统按需分配就是了，但是如果进程在运行时试图增长，就会导致问题。如果该进程相邻区域空闲，则可以扩大它的空间，若其相邻区域已被其他进程占据，则需要将其移动到一块内存中足够大的区域去，若内存已满，则需要将若干其他进程换走，直到空出足够大的空间。显然，这么做很费时。

![](/images/现代操作系统/预留内存空间.png)

一种解决方法是在分配时预留一段供其增长的数据段。

### 空闲内存管理
在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方法跟踪内存使用情况：位图和空闲链表。

**使用位图的存储管理**
位图法要求将内存划分成几个字节到几千字节的分配单元，每个分配单元对应位图中的一位，用0和1表示空闲和占用。

![](/images/现代操作系统/位图和链表.png)

分配单元的大小是一个重要的设计因素。分配单元越小，位图越大，实际可用内存就越小，但分配单元越大，浪费的内存也越大，因为只能分配整数个单元。
另外，在决定把一个占k个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有k个连续0的串，这是个耗时的操作。

**使用链表的存储管理**
另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表。如上图c所示。
当系统要为进程分配内存时，会沿着链表进行搜索，直到找到一个足够大的空闲区。
最简单的算法是首次适配法（first fit），找到的第一个足够大的空间就供进程使用，该空间剩余的部分作为新的空闲区。首次适配法速度较快，因为它尽可能少地搜索链表结点。
另一个算法时最佳适配法（best fit），它搜索整个链表，选择能够容纳进程的最小的空闲区。它比首次匹配法要慢，因为搜索整个链表，但出乎意料的是，它反而比首次匹配法更浪费内存，因为它会产生大量无用的小空闲区域。
此时，作为一名刷过算法的程序员，能敏锐地察觉到对这两种算法有不少加速的可能，比如为进程和空闲区各自维护独立的链表，这样就能只检查空闲区链表。另外还能对链表排序，这样就进一步缩短了搜索的时间。
还有一种算法称为快速适配（quick fit），它为常用大小的空闲区维护单独的链表，比如4KB一个链表，8KB一个链表，以此类推，这样系统就可以根据需要，选择合适的大小来用。

## 虚拟内存
虽然交换理论上来说可行，但实际上并不是一个具有吸引力的方案，因为一个典型的SATA磁盘的峰值传输大概是每秒几百兆，这意味着需要好几秒才能换入或换出一个1GB的程序。
20世纪60年代采取的一种解决方案是：把程序分割成许多片段，称为覆盖（overlay）。分割后的程序依次加载进入内存，以此做到小内存运行大程序。但注意，这个分割是由程序员完成的，这通常十分枯燥且复杂，显然，这种做法很快被淘汰了。
因此，一种新方法产生了，虚拟内存（virtual memory）。虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割成很多块，每一块称作一页或页面（page）。每一页有连续的地址范围，这些页被映射到物理内存，但并非所有页都在内存中才能运行程序，当程序引用到在物理内存中的地址空间时，硬件立刻执行必要的映射，当引用到不再物理内存中的地址空间时，由操作系统负责将缺失的部分装入内存并重新执行指令。
虚拟内存很适合在多道程序设计系统中使用，许多程序的片段保存在内存中，当一个程序等待它的一部分读入内存时，就可以把CPU交给另一个进程使用。

### 分页
大部分虚拟内存系统中都使用一种称为分页（paging）的技术。当程序执行指令
```
MOV REG, 1000
```
时，它把地址为1000的内存单元内容复制到REG中（或者相反，这取决与计算机的型号）。在没有虚拟内存的计算机上，系统直接将该地址送到内存总线上，读写相应的物理地址；而在使用虚拟内存的情况下，虚拟地址被送到内存管理单元（Memory Management Unit，MMU），MMU把虚拟地址映射为物理内存地址。

![](/images/现代操作系统/虚拟内存.png)

但是这并没有解决虚拟内存地址空间比物理内存大的问题。在实际的硬件中，用一个“在/不在”位（present/absent bit）记录页面在内存中的实际存在情况。如果程序访问了一个“不在”的页面，MMU会注意到该页面没有被映射，于是使CPU陷入操作系统，这个陷阱被称为缺页中断或缺页错误（page fault）。操作系统找到一个很少使用的页框（物理内存中对应的单元，page frame）把它写入磁盘，然后把需要访问的页面读到刚才回收的页框中，修改映射关系，最后重新启动引起陷阱的指令。

### 页表
页表的目的是把虚拟页面映射为页框，从数学角度说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。

**页表项的结构**
![](/images/现代操作系统/页表项)

不同计算机的页表项大小可能不一样，但32位是一个常用的大小。最重要的是页框号，其次是“在/不在”位。保护位指出一个一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。为了记录页面的使用状况，引入了修改位和访问位。修改位也被称为脏位，它表示该页面是否被修改过，修改过的页面需要重新写回磁盘，而未修改过的直接丢弃即可。访问位记录该页是否被访问过，方便操作系统决定淘汰哪一个页面。最后一位用于禁止页面被高速缓存，通常用于虚拟内存映射I/O设备，我们希望拿到的是最新的I/O设备的值而不是一个旧的被缓存的值，因此禁止它被缓存从而使CPU必须访问内存。
需要注意的是，页表不保存某页对应的磁盘地址，这个信息是操作系统自己内部保存的。

虚拟内存的本质是用来创造一个新的抽象概念--地址空间，这个概念是对物理内存的抽象，类似于进程是对物理处理器（CPU）的抽象。虚拟内存的实现，是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框。

### 加速分页过程

